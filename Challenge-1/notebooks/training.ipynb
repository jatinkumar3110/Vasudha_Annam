{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825b3483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Model Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12295c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import UnidentifiedImageError, Image\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64f8b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Key values\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 8\n",
    "LR = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a6431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== LOAD CSV ==== #\n",
    "df = pd.read_csv(train_csv)\n",
    "df['filename'] = df['image_id'].apply(lambda x: os.path.join(TRAIN_DIR, x))\n",
    "label2idx = {label: i for i, label in enumerate(df['soil_type'].unique())}\n",
    "idx2label = {i: label for label, i in label2idx.items()}\n",
    "df['label_idx'] = df['soil_type'].map(label2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09056e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== WEIGHTED SAMPLER ==== #\n",
    "class_counts = df['label_idx'].value_counts().to_dict()\n",
    "weights = df['label_idx'].map(lambda x: 1.0 / class_counts[x])\n",
    "sampler = WeightedRandomSampler(weights.values, len(weights))\n",
    "\n",
    "# ==== DATASET CLASS ==== #\n",
    "class SoilDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = Image.open(row['filename']).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = row.get('label_idx', -1)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9387dc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== TRANSFORMS ==== #\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=Image.BICUBIC),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE), interpolation=Image.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# ==== DATALOADERS ==== #\n",
    "dataset = SoilDataset(df, transform=transform_train)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=sampler)\n",
    "\n",
    "# ==== MODEL ==== #\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, len(label2idx))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc0477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== TRAINING ==== #\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in tqdm(dataloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct / total\n",
    "    train_losses.append(avg_loss)\n",
    "    train_accuracies.append(accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d277e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(range(1, EPOCHS+1), train_losses, marker='o')\n",
    "plt.title(\"Training Loss per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(1, EPOCHS+1), train_accuracies, marker='o', color='orange')\n",
    "plt.title(\"Training Accuracy per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9e3589",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in DataLoader(dataset, batch_size=BATCH_SIZE):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = outputs.max(1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148f524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(all_labels, all_preds, target_names=[idx2label[i] for i in range(len(idx2label))], digits=4)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "print(f\"Macro F1 Score: {macro_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0936951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=[idx2label[i] for i in range(len(idx2label))],\n",
    "            yticklabels=[idx2label[i] for i in range(len(idx2label))], cmap='Blues')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77c7961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "bal_acc = balanced_accuracy_score(all_labels, all_preds)\n",
    "print(f\"Balanced Accuracy: {bal_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6855be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== SAVE MODEL ==== #  weights\n",
    "torch.save(model.state_dict(), 'soil_challenge_1_resnet18.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffe7765",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saing complete model\n",
    "torch.save(model, \"best_model_challenge_1_full.pt\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
